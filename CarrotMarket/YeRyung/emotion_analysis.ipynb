{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1 - '구': 대구, 행 개수: 30\n",
      "DataFrame 2 - '구': 문구, 행 개수: 15\n",
      "DataFrame 3 - '구': 관악구, 행 개수: 14\n",
      "DataFrame 4 - '구': 송파구, 행 개수: 10\n",
      "DataFrame 5 - '구': 가구, 행 개수: 8\n",
      "DataFrame 6 - '구': 선거구, 행 개수: 7\n",
      "DataFrame 7 - '구': 연구, 행 개수: 7\n",
      "DataFrame 8 - '구': 용해지구, 행 개수: 7\n",
      "DataFrame 9 - '구': 최용구, 행 개수: 6\n",
      "DataFrame 10 - '구': 서구, 행 개수: 4\n",
      "DataFrame 11 - '구': 환풍구, 행 개수: 4\n",
      "DataFrame 12 - '구': 강서구, 행 개수: 3\n",
      "DataFrame 13 - '구': 서초구, 행 개수: 3\n",
      "DataFrame 14 - '구': 배기구, 행 개수: 1\n",
      "DataFrame 15 - '구': 중구, 행 개수: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-c22e2cd99390>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_rows['구'] = filtered_rows['기사 내용'].str.extract(location_pattern)\n"
     ]
    }
   ],
   "source": [
    "#1. 구 별로 모으기\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv(r\"C:\\Users\\yeryu\\Desktop\\빅데프 최최종\\Term_Project-1\\CarrotMarket\\JiHyeon\\AutoCrawling\\PoliceNews.csv\")\n",
    "\n",
    "# 정규 표현식 패턴\n",
    "location_pattern = r'\\b(\\w+구)\\b'\n",
    "\n",
    "# 정규 표현식 패턴이 포함된 행 추출\n",
    "filtered_rows = df[df['기사 내용'].str.contains(location_pattern, na=False, case=False, regex=True)]\n",
    "\n",
    "# 각 행의 위치 정보에서 '구' 추출\n",
    "filtered_rows['구'] = filtered_rows['기사 내용'].str.extract(location_pattern)\n",
    "\n",
    "# '구'로 묶어서 각각의 데이터프레임을 만들 리스트 초기화\n",
    "grouped_gu = []\n",
    "\n",
    "# '구' 단어를 기준으로 그룹화하여 각각의 데이터프레임을 만들어 리스트에 추가\n",
    "for location, group in filtered_rows.groupby('구'):\n",
    "    grouped_gu.append(group)\n",
    "\n",
    "# 데이터프레임을 행 개수에 따라 정렬\n",
    "sorted_gu = sorted(grouped_gu, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "# 결과 출력 (각각의 데이터프레임을 사용하려면 sorted_dfs 리스트를 활용)\n",
    "for idx, df_group in enumerate(sorted_gu):\n",
    "    print(f\"DataFrame {idx + 1} - '구': {df_group['구'].iloc[0]}, 행 개수: {len(df_group)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1 - '동': 아동, 행 개수: 39\n",
      "DataFrame 2 - '동': 시동, 행 개수: 20\n",
      "DataFrame 3 - '동': 소방활동, 행 개수: 11\n",
      "DataFrame 4 - '동': 연동, 행 개수: 10\n",
      "DataFrame 5 - '동': 가동, 행 개수: 9\n",
      "DataFrame 6 - '동': 합동, 행 개수: 9\n",
      "DataFrame 7 - '동': 활동, 행 개수: 8\n",
      "DataFrame 8 - '동': 행동, 행 개수: 6\n",
      "DataFrame 9 - '동': 유동, 행 개수: 5\n",
      "DataFrame 10 - '동': 경찰활동, 행 개수: 4\n",
      "DataFrame 11 - '동': 고기동, 행 개수: 4\n",
      "DataFrame 12 - '동': 영동, 행 개수: 4\n",
      "DataFrame 13 - '동': 목동, 행 개수: 3\n",
      "DataFrame 14 - '동': 석현동, 행 개수: 3\n",
      "DataFrame 15 - '동': 민관합동, 행 개수: 2\n",
      "DataFrame 16 - '동': 석촌동, 행 개수: 2\n",
      "DataFrame 17 - '동': 괴정동, 행 개수: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-e9db4a3b3e4a>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_rows['동'] = filtered_rows['기사 내용'].str.extract(location_pattern)\n"
     ]
    }
   ],
   "source": [
    "#2. 동 별로 모으기\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv(r\"C:\\Users\\yeryu\\Desktop\\빅데프 최최종\\Term_Project-1\\CarrotMarket\\JiHyeon\\AutoCrawling\\PoliceNews.csv\")\n",
    "\n",
    "# 정규 표현식 패턴\n",
    "location_pattern = r'\\b(\\w+동)\\b'\n",
    "\n",
    "# 정규 표현식 패턴이 포함된 행 추출\n",
    "filtered_rows = df[df['기사 내용'].str.contains(location_pattern, na=False, case=False, regex=True)]\n",
    "\n",
    "# 각 행의 위치 정보에서 '동; 추출\n",
    "filtered_rows['동'] = filtered_rows['기사 내용'].str.extract(location_pattern)\n",
    "\n",
    "# '동'로 묶어서 각각의 데이터프레임을 만들 리스트 초기화\n",
    "grouped_dong = []\n",
    "\n",
    "# '동' 단어를 기준으로 그룹화하여 각각의 데이터프레임을 만들어 리스트에 추가\n",
    "for location, group in filtered_rows.groupby('동'):\n",
    "    grouped_dong.append(group)\n",
    "\n",
    "# 데이터프레임을 행 개수에 따라 정렬\n",
    "sorted_dong = sorted(grouped_dong, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "# 결과 출력 (각각의 데이터프레임을 사용하려면 sorted_dfs 리스트를 활용)\n",
    "for idx, df_group in enumerate(sorted_dong):\n",
    "    print(f\"DataFrame {idx + 1} - '동': {df_group['동'].iloc[0]}, 행 개수: {len(df_group)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>기사 내용</th>\n",
       "      <th>타임스탬프</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>서초구, 어린이보호구역 노란색 횡단보도 신설 · 옐로카펫 확대</td>\n",
       "      <td>전성수 구청장 “어린이 교통안전 사각지대 없도록 촘촘하게 보호”\\r\\n\\r\\n계성초...</td>\n",
       "      <td>2023-12-06 01:29:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>서초구, 어린이보호구역 노란색 횡단보도 신설 · 옐로카펫 확대</td>\n",
       "      <td>전성수 구청장 “어린이 교통안전 사각지대 없도록 촘촘하게 보호”\\r\\n\\r\\n계성초...</td>\n",
       "      <td>2023-12-06 01:34:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>서초구, 어린이보호구역 노란색 횡단보도 신설 · 옐로카펫 확대</td>\n",
       "      <td>전성수 구청장 “어린이 교통안전 사각지대 없도록 촘촘하게 보호”\\r\\n\\r\\n계성초...</td>\n",
       "      <td>2023-12-06 01:39:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     제목  \\\n",
       "224  서초구, 어린이보호구역 노란색 횡단보도 신설 · 옐로카펫 확대   \n",
       "236  서초구, 어린이보호구역 노란색 횡단보도 신설 · 옐로카펫 확대   \n",
       "247  서초구, 어린이보호구역 노란색 횡단보도 신설 · 옐로카펫 확대   \n",
       "\n",
       "                                                 기사 내용                타임스탬프  \n",
       "224  전성수 구청장 “어린이 교통안전 사각지대 없도록 촘촘하게 보호”\\r\\n\\r\\n계성초...  2023-12-06 01:29:33  \n",
       "236  전성수 구청장 “어린이 교통안전 사각지대 없도록 촘촘하게 보호”\\r\\n\\r\\n계성초...  2023-12-06 01:34:29  \n",
       "247  전성수 구청장 “어린이 교통안전 사각지대 없도록 촘촘하게 보호”\\r\\n\\r\\n계성초...  2023-12-06 01:39:26  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 단어 모으기 <- hbase에서 단어 찾기..?\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv(r\"C:\\Users\\yeryu\\Desktop\\빅데프 최최종\\Term_Project-1\\CarrotMarket\\JiHyeon\\AutoCrawling\\PoliceNews.csv\")\n",
    "\n",
    "\n",
    "# 특정 단어가 포함된 행 추출\n",
    "target_word = '서초구'  # 원하는 단어로 변경\n",
    "filtered_df = df[df['기사 내용'].str.contains(target_word, case=False, na=False)]\n",
    "\n",
    "# 결과 출력\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-33\n"
     ]
    }
   ],
   "source": [
    "#3. 특정 단어 포함된 기사들 - 감성점수 평균 구하기  \n",
    "\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json\n",
    "import re\n",
    "\n",
    "class KnuSL():\n",
    "    def __init__(self):\n",
    "        with open('C:/Users/yeryu/Desktop/빅데프 최최종/Term_Project-1/CarrotMarket/YeRyung/SentiWord_info.json', encoding='utf-8-sig', mode='r') as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "    def data_list(self, wordname):\n",
    "        result = ['None', 'None']\n",
    "        for i in range(0, len(self.data)):\n",
    "            if self.data[i]['word'] == wordname:\n",
    "                result.pop()\n",
    "                result.pop()\n",
    "                result.append(self.data[i]['word_root'])\n",
    "                result.append(self.data[i]['polarity'])\n",
    "\n",
    "        r_word = result[0]\n",
    "        s_word = result[1]\n",
    "\n",
    "        return s_word\n",
    "\n",
    "def knuSL(word):\n",
    "    ksl = KnuSL()\n",
    "    wordname = word.strip(\" \")\n",
    "    return ksl.data_list(wordname)\n",
    "\n",
    "def sensibility(arr):\n",
    "    grade = 0  # 감정 점수\n",
    "    for content in arr:\n",
    "        for word in content:\n",
    "            # 감성분석 (KNU 한국어 감성 사전)\n",
    "            data = knuSL(word)\n",
    "            if (data != None and data != \"None\"):\n",
    "                grade += int(data)\n",
    "    return grade\n",
    "\n",
    "# 불용어 제거\n",
    "def stopword_cleaner(text):\n",
    "    # 1차 정제\n",
    "    text = re.sub(pattern='([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)', repl=\"\", string=text)\n",
    "    text = re.sub(pattern='<[^>]*>', repl=\"\", string=text)\n",
    "    text = re.sub(pattern='[^\\w\\s]', repl=\"\", string=text)\n",
    "    text = re.sub(pattern='[0-9]+', repl=\"\", string=text)\n",
    "\n",
    "    return text.split()\n",
    "\n",
    "def main():\n",
    "    # 데이터프레임 or CSV 파일 불러오기\n",
    "    df = filtered_df     #sorted_gu[2]    # '구' 단어 중 숫자 바꿔서 데이터프레임 선택\n",
    "    sensibilityGrade = 0\n",
    "    sensibilitySum = 0\n",
    "    \n",
    "    for i in df['기사 내용']:\n",
    "        try:\n",
    "            # 불용어 제거\n",
    "            cleanArr = stopword_cleaner(i)\n",
    "\n",
    "            # 감성분석 (KNU 한국어 감성 사전)\n",
    "            sensibilityGrade = sensibility(cleanArr)\n",
    "            sensibilitySum += sensibilityGrade\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text: {e}\")\n",
    "        \n",
    "    # 계산한 감성 점수의 평균 출력\n",
    "    print(sensibilitySum)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
